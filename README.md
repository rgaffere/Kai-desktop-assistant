# Kai â€“ Desktop AI Assistant (Prototype)

**Kai** is a real-time desktop assistant that captures screen content and audio, interprets the userâ€™s environment, and responds through an intelligent overlay and voice. It was built as a personal project to explore a multimodal J.A.R.V.I.S.-like assistant.

Although functional, **Kai is now deprecated** as development has shifted to a more advanced successor system.

---

## ğŸ§  Features

- ğŸ¤ **Voice & Screen Context**: Captures screen via macOS CoreGraphics and voice (placeholder) to form a prompt.
- ğŸ¤– **Intent Classification**: Lightweight Python classifier decides if GPT should be called or action taken locally.
- ğŸ’¬ **GPT-4o Integration**: Streamed responses using OpenAIâ€™s GPT-4o with Node.js and Axios.
- ğŸ—£ï¸ **Text-to-Speech (TTS)**: Real-time ElevenLabs voice playback with stream-based synthesis.
- ğŸ’» **Overlay UI**: JSON-driven response display rendered by a Tauri-based frontend.
  
---

## âš™ï¸ Requirements

- macOS (for screen capture APIs)
- C++17 compiler (e.g. clang)
- Node.js â‰¥ 18
- Python â‰¥ 3.8
- Dependencies:
  - [Tesseract OCR](https://github.com/tesseract-ocr/tesseract)
  - [ElevenLabs API key](https://www.elevenlabs.io/)
  - [OpenAI API key](https://platform.openai.com/)
  - Tauri frontend running in `kai-overlay`

---

## âœï¸ Author

Created by **Ryan G** as a personal project and experiment in real-time AI interface design.
